{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Features \n",
    "1. Embedding Score\n",
    "2. One Hot Encoded Effect Features: \n",
    "   ```     # Neue One-Hot Encoded Effekt-Kategorien (Boolean-Spalten)\n",
    "    effect_search = Column(Boolean, default=False)\n",
    "    effect_destroy = Column(Boolean, default=False)\n",
    "    effect_negate = Column(Boolean, default=False)\n",
    "    effect_draw = Column(Boolean, default=False)\n",
    "    effect_special_summon = Column(Boolean, default=False)\n",
    "    effect_banish = Column(Boolean, default=False)\n",
    "    effect_send_gy = Column(Boolean, default=False)\n",
    "    effect_recover_lp = Column(Boolean, default=False)\n",
    "    effect_inflict_damage = Column(Boolean, default=False)\n",
    "    effect_equip = Column(Boolean, default=False)\n",
    "    effect_modify_stats = Column(Boolean, default=False)\n",
    "    effect_protect = Column(Boolean, default=False)\n",
    "    effect_discard = Column(Boolean, default=False)\n",
    "    effect_change_position = Column(Boolean, default=False)\n",
    "    effect_return = Column(Boolean, default=False)\n",
    "    effect_shuffle = Column(Boolean, default=False)\n",
    "    effect_copy = Column(Boolean, default=False)\n",
    "    effect_counter = Column(Boolean, default=False)\n",
    "    effect_token_summon = Column(Boolean, default=False)\n",
    "    effect_deck_manipulation = Column(Boolean, default=False)\n",
    "```\n",
    "- Normalizierte Anzahl anvorhandenen reffernzierten Karten (0-1)\n",
    "- Normalisierte Anzahl an anvorhandn refnezierten Achetps\n",
    "- Normalisierte Anzahl an vorhandenen refnezierten Races in Decks \n",
    "- ban satus number (0-3)\n",
    "-is_staple Card\n",
    "\n",
    "- Anzahl an verschiedenne Card Types in Deck prozentual\n",
    "- emedding score\n",
    "- normalisierte Anzhal an sysnergien aus apiroi analysis\n",
    "- same archetype \n",
    "- same race\n",
    "- TF_IDF score der Karte \n",
    "\n",
    "\n"
   ],
   "id": "917a0236c730086d"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-02-21T08:57:53.597967Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "train_ml_reranker_rf_db_with_embeddings.py\n",
    "\n",
    "Dieses Skript lädt Decks und Karten aus der DB, berechnet\n",
    "verschiedene Features (inklusive eines Embedding Scores, der\n",
    "auf vorab gespeicherten Graph-Embeddings basiert) und trainiert\n",
    "einen RandomForest, der als Re-Ranker verwendet werden kann.\n",
    "\"\"\"\n",
    "\n",
    "import pickle\n",
    "import random\n",
    "import math\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "# SQLAlchemy\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "# DB-Modelle\n",
    "from db.models import Base, Deck, DeckCard, Card\n",
    "\n",
    "# ----------------- Embeddings laden -----------------\n",
    "EMBEDDINGS_PICKLE = \"graph_embeddings.pkl\"  # Pfad zur Pickle-Datei mit den Embeddings\n",
    "\n",
    "try:\n",
    "    with open(EMBEDDINGS_PICKLE, \"rb\") as f:\n",
    "        embeddings_dict = pickle.load(f)\n",
    "    print(f\"Es wurden {len(embeddings_dict)} Embeddings aus '{EMBEDDINGS_PICKLE}' geladen.\")\n",
    "except Exception as e:\n",
    "    print(f\"Fehler beim Laden der Embeddings: {e}\")\n",
    "    embeddings_dict = {}\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# Angepasste get_embedding_score-Funktion\n",
    "# -----------------------------------------------------\n",
    "def get_embedding_score(deck_cards, c_id):\n",
    "    \"\"\"\n",
    "    Berechnet den Embedding Score als Cosinus-Ähnlichkeit zwischen\n",
    "    dem durchschnittlichen Deck-Embedding (über alle Karten des Decks)\n",
    "    und dem Embedding der Kandidatenkarte.\n",
    "    Falls ein Embedding nicht gefunden wird, wird 0.0 zurückgegeben.\n",
    "    \"\"\"\n",
    "    if c_id not in embeddings_dict:\n",
    "        return 0.0\n",
    "    candidate_vector = np.array(embeddings_dict[c_id])\n",
    "    deck_vectors = [np.array(embeddings_dict[x]) for x in deck_cards if x in embeddings_dict]\n",
    "    if not deck_vectors:\n",
    "        return 0.0\n",
    "    deck_avg = np.mean(deck_vectors, axis=0)\n",
    "    dot = np.dot(candidate_vector, deck_avg)\n",
    "    norm_candidate = np.linalg.norm(candidate_vector)\n",
    "    norm_deck = np.linalg.norm(deck_avg)\n",
    "    if norm_candidate == 0 or norm_deck == 0:\n",
    "        return 0.0\n",
    "    return float(dot / (norm_candidate * norm_deck))\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1) Daten aus DB laden\n",
    "# ---------------------------------------------------------\n",
    "def load_decks_and_cards_from_db(db_url=\"sqlite:///mydb.db\"):\n",
    "    \"\"\"\n",
    "    Lädt alle Decks aus der DB.\n",
    "    Gibt zurück:\n",
    "      - deck_list: Liste von Deck-Objekten\n",
    "      - all_cards: Set aller card_ids, die in der DB jemals vorkommen.\n",
    "    \"\"\"\n",
    "    engine = create_engine(db_url)\n",
    "    Session = sessionmaker(bind=engine)\n",
    "    session = Session()\n",
    "\n",
    "    deck_list = session.query(Deck).all()\n",
    "    all_cards = set()\n",
    "    for deck in deck_list:\n",
    "        for dc in deck.deck_cards:\n",
    "            all_cards.add(dc.card_id)\n",
    "\n",
    "    session.close()\n",
    "    return deck_list, all_cards\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2) card_info_fn: Holt alle benötigten Attribute aus DB\n",
    "# ---------------------------------------------------------\n",
    "def card_info_fn_factory(db_url=\"sqlite:///mydb.db\"):\n",
    "    \"\"\"\n",
    "    Gibt eine Funktion zurück, die card_info_fn(c_id) aufruft und\n",
    "    SQLAlchemy nutzt, um alle nötigen Features zu liefern.\n",
    "    \"\"\"\n",
    "    def card_info_fn(c_id):\n",
    "        engine = create_engine(db_url)\n",
    "        Session = sessionmaker(bind=engine)\n",
    "        session = Session()\n",
    "        try:\n",
    "            card_obj = session.query(Card).filter(Card.id == c_id).first()\n",
    "            if card_obj:\n",
    "                # Banstatus aus ban_tcg (Beispiel)\n",
    "                ban_status = card_obj.ban_tcg\n",
    "                if ban_status:\n",
    "                    if ban_status.lower() == \"banned\":\n",
    "                        ban_status_num = 0\n",
    "                    elif ban_status.lower() == \"limited\":\n",
    "                        ban_status_num = 1\n",
    "                    elif ban_status.lower() == \"semi-limited\":\n",
    "                        ban_status_num = 2\n",
    "                    else:\n",
    "                        ban_status_num = 3\n",
    "                else:\n",
    "                    ban_status_num = 3\n",
    "\n",
    "                # JSON-Felder parsen\n",
    "                try:\n",
    "                    referenced_cards = json.loads(card_obj.referenced_cards) if card_obj.referenced_cards else []\n",
    "                except Exception:\n",
    "                    referenced_cards = []\n",
    "                try:\n",
    "                    referenced_archetypes = json.loads(card_obj.referenced_archetypes) if card_obj.referenced_archetypes else []\n",
    "                except Exception:\n",
    "                    referenced_archetypes = []\n",
    "                try:\n",
    "                    referenced_races = json.loads(card_obj.referenced_races) if card_obj.referenced_races else []\n",
    "                except Exception:\n",
    "                    referenced_races = []\n",
    "\n",
    "                return {\n",
    "                    \"id\": card_obj.id,\n",
    "                    \"name\": card_obj.name,\n",
    "                    \"type\": card_obj.type or \"\",\n",
    "                    \"human_readable_card_type\": card_obj.human_readable_card_type,\n",
    "                    \"frame_type\": card_obj.frame_type,\n",
    "                    \"desc\": card_obj.desc,\n",
    "                    \"race\": card_obj.race,\n",
    "                    \"archetype\": card_obj.archetype,\n",
    "                    \"ban_status_num\": ban_status_num,\n",
    "                    \"is_staple\": card_obj.is_staple,\n",
    "                    # One-Hot Encoded Effekt-Features:\n",
    "                    \"effect_search\": card_obj.effect_search,\n",
    "                    \"effect_destroy\": card_obj.effect_destroy,\n",
    "                    \"effect_negate\": card_obj.effect_negate,\n",
    "                    \"effect_draw\": card_obj.effect_draw,\n",
    "                    \"effect_special_summon\": card_obj.effect_special_summon,\n",
    "                    \"effect_banish\": card_obj.effect_banish,\n",
    "                    \"effect_send_gy\": card_obj.effect_send_gy,\n",
    "                    \"effect_recover_lp\": card_obj.effect_recover_lp,\n",
    "                    \"effect_inflict_damage\": card_obj.effect_inflict_damage,\n",
    "                    \"effect_equip\": card_obj.effect_equip,\n",
    "                    \"effect_modify_stats\": card_obj.effect_modify_stats,\n",
    "                    \"effect_protect\": card_obj.effect_protect,\n",
    "                    \"effect_discard\": card_obj.effect_discard,\n",
    "                    \"effect_change_position\": card_obj.effect_change_position,\n",
    "                    \"effect_return\": card_obj.effect_return,\n",
    "                    \"effect_shuffle\": card_obj.effect_shuffle,\n",
    "                    \"effect_copy\": card_obj.effect_copy,\n",
    "                    \"effect_counter\": card_obj.effect_counter,\n",
    "                    \"effect_token_summon\": card_obj.effect_token_summon,\n",
    "                    \"effect_deck_manipulation\": card_obj.effect_deck_manipulation,\n",
    "                    # Referenzierte Attribute\n",
    "                    \"referenced_cards\": referenced_cards,\n",
    "                    \"referenced_archetypes\": referenced_archetypes,\n",
    "                    \"referenced_races\": referenced_races,\n",
    "                    # Dummy TF_IDF Score\n",
    "                    \"tf_idf\": 0.5\n",
    "                }\n",
    "            else:\n",
    "                return {\n",
    "                    \"id\": c_id,\n",
    "                    \"name\": \"\",\n",
    "                    \"type\": \"\",\n",
    "                    \"human_readable_card_type\": \"\",\n",
    "                    \"frame_type\": \"\",\n",
    "                    \"desc\": \"\",\n",
    "                    \"race\": None,\n",
    "                    \"archetype\": None,\n",
    "                    \"ban_status_num\": 3,\n",
    "                    \"is_staple\": False,\n",
    "                    \"effect_search\": False,\n",
    "                    \"effect_destroy\": False,\n",
    "                    \"effect_negate\": False,\n",
    "                    \"effect_draw\": False,\n",
    "                    \"effect_special_summon\": False,\n",
    "                    \"effect_banish\": False,\n",
    "                    \"effect_send_gy\": False,\n",
    "                    \"effect_recover_lp\": False,\n",
    "                    \"effect_inflict_damage\": False,\n",
    "                    \"effect_equip\": False,\n",
    "                    \"effect_modify_stats\": False,\n",
    "                    \"effect_protect\": False,\n",
    "                    \"effect_discard\": False,\n",
    "                    \"effect_change_position\": False,\n",
    "                    \"effect_return\": False,\n",
    "                    \"effect_shuffle\": False,\n",
    "                    \"effect_copy\": False,\n",
    "                    \"effect_counter\": False,\n",
    "                    \"effect_token_summon\": False,\n",
    "                    \"effect_deck_manipulation\": False,\n",
    "                    \"referenced_cards\": [],\n",
    "                    \"referenced_archetypes\": [],\n",
    "                    \"referenced_races\": [],\n",
    "                    \"tf_idf\": 0.5\n",
    "                }\n",
    "        finally:\n",
    "            session.close()\n",
    "    return card_info_fn\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3) Hilfsfunktionen (Feature-Building etc.)\n",
    "# ---------------------------------------------------------\n",
    "def build_feature_vector(deck_cards, c_id, usage_stats, combos,\n",
    "                         get_embedding_score, card_info_fn):\n",
    "    \"\"\"\n",
    "    Erzeugt einen Feature-Vektor für die (Deck, Candidate)-Kombination.\n",
    "    Folgende Features werden berücksichtigt:\n",
    "      0  - Embedding Score (Cosinus-Ähnlichkeit)\n",
    "      1  - Normalisierte Usage-Statistik\n",
    "      2  - Normalisierte Synergie (basierend auf frequent combos)\n",
    "      3  - Anteil Spell-Karten im Deck\n",
    "      4  - Anteil Trap-Karten im Deck\n",
    "      5  - Anteil Monster-Karten im Deck\n",
    "      6  - Ban-Status (0-3)\n",
    "      7  - Anzahl gleicher Archetypen im Deck\n",
    "      8  - Anzahl gleicher Races im Deck\n",
    "      9  - Normalisierte Anzahl referenzierter Karten (Candidate in Deck)\n",
    "      10 - Normalisierte Anzahl referenzierter Archetypen (Candidate in Deck)\n",
    "      11 - Normalisierte Anzahl referenzierter Races (Candidate in Deck)\n",
    "      12 - is_staple (1/0)\n",
    "      13-32 - One-Hot Encoded Effekt-Features (20 Features)\n",
    "      33 - TF_IDF Score\n",
    "    \"\"\"\n",
    "    deck_set = set(deck_cards)\n",
    "    embedding_score = get_embedding_score(deck_cards, c_id)\n",
    "    usage_val = usage_stats.get(c_id, 0.0)\n",
    "\n",
    "    # Synergy: Zähle, wie viele frequent combos (mit Aufnahme der Candidate) erfüllt sind.\n",
    "    synergy_count = 0\n",
    "    new_deck = deck_set.union({c_id})\n",
    "    for combo_dict in combos:\n",
    "        combo_items = combo_dict[\"itemsets\"]  # Liste von Card-IDs\n",
    "        combo_set = set(map(int, combo_items))\n",
    "        if combo_set.issubset(new_deck):\n",
    "            synergy_count += 1\n",
    "    synergy_norm = synergy_count / len(deck_cards) if deck_cards else 0\n",
    "\n",
    "    # Deck-Komposition und Sammlung von Archetypen/Races\n",
    "    spell_count = 0\n",
    "    trap_count = 0\n",
    "    monster_count = 0\n",
    "    deck_archetypes = []\n",
    "    deck_races = []\n",
    "    for dcard in deck_cards:\n",
    "        info = card_info_fn(dcard)\n",
    "        ctype = info.get(\"type\", \"\")\n",
    "        if \"Spell\" in ctype:\n",
    "            spell_count += 1\n",
    "        elif \"Trap\" in ctype:\n",
    "            trap_count += 1\n",
    "        else:\n",
    "            monster_count += 1\n",
    "        arch = info.get(\"archetype\")\n",
    "        if arch:\n",
    "            deck_archetypes.append(arch)\n",
    "        race = info.get(\"race\")\n",
    "        if race:\n",
    "            deck_races.append(race)\n",
    "    total_cards = len(deck_cards) if deck_cards else 1\n",
    "    spell_pct = spell_count / total_cards\n",
    "    trap_pct = trap_count / total_cards\n",
    "    monster_pct = monster_count / total_cards\n",
    "\n",
    "    # Informationen zur Candidate-Karte\n",
    "    cand_info = card_info_fn(c_id)\n",
    "    ban_stat = cand_info.get(\"ban_status_num\", 3)\n",
    "    cand_arche = cand_info.get(\"archetype\")\n",
    "    cand_race = cand_info.get(\"race\")\n",
    "    same_arch_count = sum(1 for a in deck_archetypes if a == cand_arche) if cand_arche else 0\n",
    "    same_race_count = sum(1 for r in deck_races if r == cand_race) if cand_race else 0\n",
    "\n",
    "    # Normalisierte referenzierte Karten\n",
    "    referenced_cards = cand_info.get(\"referenced_cards\", [])\n",
    "    num_ref_cards = len(referenced_cards)\n",
    "    count_ref_cards_in_deck = 0\n",
    "    for ref in referenced_cards:\n",
    "        try:\n",
    "            ref_int = int(ref)\n",
    "        except ValueError:\n",
    "            continue\n",
    "        if ref_int in deck_set:\n",
    "            count_ref_cards_in_deck += 1\n",
    "    norm_ref_cards = count_ref_cards_in_deck / num_ref_cards if num_ref_cards > 0 else 0\n",
    "\n",
    "    # Normalisierte referenzierte Archetypen\n",
    "    referenced_archetypes = cand_info.get(\"referenced_archetypes\", [])\n",
    "    num_ref_arch = len(referenced_archetypes)\n",
    "    count_ref_arch_in_deck = sum(1 for ref in referenced_archetypes if ref in deck_archetypes)\n",
    "    norm_ref_arch = count_ref_arch_in_deck / num_ref_arch if num_ref_arch > 0 else 0\n",
    "\n",
    "    # Normalisierte referenzierte Races\n",
    "    referenced_races = cand_info.get(\"referenced_races\", [])\n",
    "    num_ref_races = len(referenced_races)\n",
    "    count_ref_races_in_deck = sum(1 for ref in referenced_races if ref in deck_races)\n",
    "    norm_ref_races = count_ref_races_in_deck / num_ref_races if num_ref_races > 0 else 0\n",
    "\n",
    "    # TF_IDF Score (Dummy)\n",
    "    tf_idf = cand_info.get(\"tf_idf\", 0.5)\n",
    "\n",
    "    # One-Hot Encoded Effekt-Features (20 Features)\n",
    "    effect_features = [\n",
    "        1 if cand_info.get(\"effect_search\") else 0,\n",
    "        1 if cand_info.get(\"effect_destroy\") else 0,\n",
    "        1 if cand_info.get(\"effect_negate\") else 0,\n",
    "        1 if cand_info.get(\"effect_draw\") else 0,\n",
    "        1 if cand_info.get(\"effect_special_summon\") else 0,\n",
    "        1 if cand_info.get(\"effect_banish\") else 0,\n",
    "        1 if cand_info.get(\"effect_send_gy\") else 0,\n",
    "        1 if cand_info.get(\"effect_recover_lp\") else 0,\n",
    "        1 if cand_info.get(\"effect_inflict_damage\") else 0,\n",
    "        1 if cand_info.get(\"effect_equip\") else 0,\n",
    "        1 if cand_info.get(\"effect_modify_stats\") else 0,\n",
    "        1 if cand_info.get(\"effect_protect\") else 0,\n",
    "        1 if cand_info.get(\"effect_discard\") else 0,\n",
    "        1 if cand_info.get(\"effect_change_position\") else 0,\n",
    "        1 if cand_info.get(\"effect_return\") else 0,\n",
    "        1 if cand_info.get(\"effect_shuffle\") else 0,\n",
    "        1 if cand_info.get(\"effect_copy\") else 0,\n",
    "        1 if cand_info.get(\"effect_counter\") else 0,\n",
    "        1 if cand_info.get(\"effect_token_summon\") else 0,\n",
    "        1 if cand_info.get(\"effect_deck_manipulation\") else 0\n",
    "    ]\n",
    "\n",
    "    # Zusammenbau des Feature-Vektors (34 Features insgesamt)\n",
    "    feat_vec = [\n",
    "        embedding_score,      # 0\n",
    "        usage_val,            # 1\n",
    "        synergy_norm,         # 2\n",
    "        spell_pct,            # 3\n",
    "        trap_pct,             # 4\n",
    "        monster_pct,          # 5\n",
    "        ban_stat,             # 6\n",
    "        same_arch_count,      # 7\n",
    "        same_race_count,      # 8\n",
    "        norm_ref_cards,       # 9\n",
    "        norm_ref_arch,        # 10\n",
    "        norm_ref_races,       # 11\n",
    "        1 if cand_info.get(\"is_staple\") else 0  # 12\n",
    "    ]\n",
    "    feat_vec.extend(effect_features)  # Features 13-32\n",
    "    feat_vec.append(tf_idf)             # Feature 33\n",
    "\n",
    "    return feat_vec\n",
    "\n",
    "\n",
    "def build_training_data(\n",
    "        deck_list,      # Liste von Deck-Objekten\n",
    "        all_cards,      # Set aller Karten-IDs\n",
    "        usage_stats,    # {card_id: float}\n",
    "        combos,         # frequent combos\n",
    "        get_embedding_score,\n",
    "        card_info_fn,\n",
    "        negative_ratio=1\n",
    "):\n",
    "    \"\"\"\n",
    "    Erzeugt (X, y) Trainingsdaten:\n",
    "      - Positive Beispiele: Karte c_id ist im Deck (Label=1)\n",
    "      - Negative Beispiele: Zufällig gewählte Karten, die nicht im Deck sind (Label=0)\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for deck in deck_list:\n",
    "        deck_cards = [dc.card_id for dc in deck.deck_cards]\n",
    "        deck_card_set = set(deck_cards)\n",
    "\n",
    "        # Positive Beispiele\n",
    "        for c_id in deck_card_set:\n",
    "            fv = build_feature_vector(deck_cards, c_id, usage_stats, combos,\n",
    "                                      get_embedding_score, card_info_fn)\n",
    "            X.append(fv)\n",
    "            y.append(1)\n",
    "\n",
    "        # Negative Beispiele\n",
    "        not_in_deck = list(all_cards - deck_card_set)\n",
    "        sample_size = min(len(not_in_deck), negative_ratio * len(deck_cards))\n",
    "        if sample_size > 0:\n",
    "            neg_cards = random.sample(not_in_deck, sample_size)\n",
    "            for c_id in neg_cards:\n",
    "                fv = build_feature_vector(deck_cards, c_id, usage_stats, combos,\n",
    "                                          get_embedding_score, card_info_fn)\n",
    "                X.append(fv)\n",
    "                y.append(0)\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "def train_random_forest(X, y):\n",
    "    \"\"\"\n",
    "    Trainiert einen RandomForestClassifier, evaluiert ihn und speichert das Modell.\n",
    "    Gibt das trainierte Modell zurück.\n",
    "    \"\"\"\n",
    "    if len(X) == 0:\n",
    "        print(\"Keine Trainingsdaten (X ist leer). Abbruch.\")\n",
    "        return None\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    if len(X_train) == 0 or len(X_test) == 0:\n",
    "        print(\"Zu wenige Samples für Train/Test-Split. Abbruch.\")\n",
    "        return None\n",
    "\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluation\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    acc = accuracy_score(y_test, (y_pred_proba > 0.5).astype(int))\n",
    "    print(f\"RandomForest -> Test AUC = {auc:.4f}, Accuracy = {acc:.4f}\")\n",
    "\n",
    "    # Speichern des Modells\n",
    "    with open(\"my_random_forest.pkl\", \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def re_rank_with_model(deck_cards, candidate_ids, model, usage_stats, combos,\n",
    "                       get_embedding_score, card_info_fn):\n",
    "    \"\"\"\n",
    "    Wendet das trainierte RandomForest-Modell an:\n",
    "    (Deck, Candidate) -> Wahrscheinlichkeit (Label=1)\n",
    "    und sortiert die Kandidaten absteigend nach Wahrscheinlichkeit.\n",
    "    \"\"\"\n",
    "    if model is None:\n",
    "        print(\"Kein Modell vorhanden. Abbruch.\")\n",
    "        return []\n",
    "\n",
    "    results = []\n",
    "    for c_id in candidate_ids:\n",
    "        fv = build_feature_vector(deck_cards, c_id, usage_stats, combos,\n",
    "                                  get_embedding_score, card_info_fn)\n",
    "        score = model.predict_proba([fv])[0][1]  # Wahrscheinlichkeit für Label=1\n",
    "        results.append((c_id, score))\n",
    "\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return results\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4) MAIN\n",
    "# ---------------------------------------------------------\n",
    "def main():\n",
    "    db_url = \"sqlite:///data.sqlite\"  # Passe den Pfad zur DB an\n",
    "    deck_list, all_cards = load_decks_and_cards_from_db(db_url)\n",
    "    print(f\"Decks geladen: {len(deck_list)}\")\n",
    "    print(f\"Insgesamt Karten-IDs (in Decks): {len(all_cards)}\")\n",
    "\n",
    "    # Berechne usage_stats: relative Häufigkeit, in wie vielen Decks eine Karte vorkommt\n",
    "    usage_stats = defaultdict(int)\n",
    "    for deck in deck_list:\n",
    "        unique_deck_cards = set(dc.card_id for dc in deck.deck_cards)\n",
    "        for c_id in unique_deck_cards:\n",
    "            usage_stats[c_id] += 1\n",
    "    for c_id in usage_stats:\n",
    "        usage_stats[c_id] = usage_stats[c_id] / len(deck_list)\n",
    "\n",
    "    # Combos laden (frequent_combos.json), falls vorhanden\n",
    "    try:\n",
    "        with open(\"frequent_combos.json\", \"r\") as f:\n",
    "            combos = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        combos = []\n",
    "        print(\"Keine frequent_combos.json gefunden. combos bleibt leer.\")\n",
    "\n",
    "    # card_info_fn\n",
    "    card_info_fn = card_info_fn_factory(db_url)\n",
    "\n",
    "    # Erstelle Trainingsdaten\n",
    "    X, y = build_training_data(\n",
    "        deck_list,\n",
    "        all_cards,\n",
    "        usage_stats,\n",
    "        combos,\n",
    "        get_embedding_score,\n",
    "        card_info_fn,\n",
    "        negative_ratio=1\n",
    "    )\n",
    "    print(f\"Trainingssamples: {X.shape[0]}\")\n",
    "    if len(X) > 0:\n",
    "        print(f\"Positive = {sum(y)}, Negative = {len(y) - sum(y)}\")\n",
    "\n",
    "    # Trainiere das Modell\n",
    "    model = train_random_forest(X, y)\n",
    "    if not model:\n",
    "        return\n",
    "\n",
    "    # Beispiel: Re-Ranking für das erste Deck aus deck_list\n",
    "    if deck_list:\n",
    "        example_deck = deck_list[0]\n",
    "        example_deck_cards = [dc.card_id for dc in example_deck.deck_cards]\n",
    "\n",
    "        # Zufällige 10 Karten aus all_cards als Kandidaten\n",
    "        candidate_ids = random.sample(all_cards, min(10, len(all_cards)))\n",
    "        results = re_rank_with_model(example_deck_cards, candidate_ids, model,\n",
    "                                     usage_stats, combos,\n",
    "                                     get_embedding_score, card_info_fn)\n",
    "        print(\"\\nRe-Ranked Candidates:\")\n",
    "        for (cid, sc) in results:\n",
    "            print(f\"Card {cid} -> Probability {sc:.3f}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ],
   "id": "13c3441f887b248a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Es wurden 10388 Embeddings aus 'graph_embeddings.pkl' geladen.\n",
      "Decks geladen: 3216\n",
      "Insgesamt Karten-IDs (in Decks): 10143\n"
     ]
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
